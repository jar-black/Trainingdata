{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# English to Swedish Poetry Translation with Unsloth\n\nThis notebook fine-tunes a language model using Unsloth to translate English poetry to Swedish.\n\n## Hardware Requirements\n- GPU: RTX 3060 (12GB) or better\n- RAM: 16GB+ recommended\n\n## Dataset\n- Training data: `english_to_swedish_poetry_translation.json`\n- **1884 translation examples** from **111 poems**\n- Format: Alpaca (instruction, input, output)\n- **Modern Swedish Poets (1940-1990 style):**\n  - Tomas TranstrÃ¶mer (Nobel Prize 2011)\n  - Harry Martinson (Nobel Prize 1974)\n  - Gunnar EkelÃ¶f\n  - Werner AspenstrÃ¶m\n  - Karin Boye\n  - Lars Gustafsson\n- Plus classic poets: Viktor Rydberg, Verner von Heidenstam, Esaias TegnÃ©r\n- Multiple granularities: full poems, stanzas, and multi-line excerpts"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting unsloth@ git+https://github.com/unslothai/unsloth.git (from unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git)\n",
      "  Cloning https://github.com/unslothai/unsloth.git to /tmp/pip-install-99bfmy7b/unsloth_04a79c7939224f498b82064221bfc26c\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/unslothai/unsloth.git /tmp/pip-install-99bfmy7b/unsloth_04a79c7939224f498b82064221bfc26c\n",
      "  Resolved https://github.com/unslothai/unsloth.git to commit e51d3ea2e498fc893770d92ca6727bd113918480\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: unsloth_zoo>=2026.1.4 in /home/johan/git/Trainingdata/venv/lib/python3.12/site-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2026.1.4)\n",
      "Requirement already satisfied: packaging in /home/johan/git/Trainingdata/venv/lib/python3.12/site-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (26.0)\n",
      "Requirement already satisfied: tyro in /home/johan/git/Trainingdata/venv/lib/python3.12/site-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (1.0.5)\n",
      "Requirement already satisfied: transformers!=4.52.0,!=4.52.1,!=4.52.2,!=4.52.3,!=4.53.0,!=4.54.0,!=4.55.0,!=4.55.1,!=4.57.0,!=4.57.4,!=4.57.5,<=4.57.6,>=4.51.3 in /home/johan/git/Trainingdata/venv/lib/python3.12/site-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (4.57.6)\n",
      "Requirement already satisfied: datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1 in /home/johan/git/Trainingdata/venv/lib/python3.12/site-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (4.3.0)\n",
      "Requirement already satisfied: sentencepiece>=0.2.0 in /home/johan/git/Trainingdata/venv/lib/python3.12/site-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.2.1)\n",
      "Requirement already satisfied: tqdm in /home/johan/git/Trainingdata/venv/lib/python3.12/site-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (4.67.1)\n",
      "Requirement already satisfied: psutil in /home/johan/git/Trainingdata/venv/lib/python3.12/site-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (7.2.2)\n",
      "Requirement already satisfied: wheel>=0.42.0 in /home/johan/git/Trainingdata/venv/lib/python3.12/site-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.46.3)\n",
      "Requirement already satisfied: numpy in /home/johan/git/Trainingdata/venv/lib/python3.12/site-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2.4.1)\n",
      "Requirement already satisfied: protobuf in /home/johan/git/Trainingdata/venv/lib/python3.12/site-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (6.33.5)\n",
      "Requirement already satisfied: huggingface_hub>=0.34.0 in /home/johan/git/Trainingdata/venv/lib/python3.12/site-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.36.0)\n",
      "Requirement already satisfied: hf_transfer in /home/johan/git/Trainingdata/venv/lib/python3.12/site-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.1.9)\n",
      "Requirement already satisfied: bitsandbytes!=0.46.0,!=0.48.0,>=0.45.5 in /home/johan/git/Trainingdata/venv/lib/python3.12/site-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.49.1)\n",
      "Requirement already satisfied: sentence-transformers in /home/johan/git/Trainingdata/venv/lib/python3.12/site-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (5.2.2)\n",
      "Requirement already satisfied: torch<3,>=2.3 in /home/johan/git/Trainingdata/venv/lib/python3.12/site-packages (from bitsandbytes!=0.46.0,!=0.48.0,>=0.45.5->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2.10.0)\n",
      "Requirement already satisfied: filelock in /home/johan/git/Trainingdata/venv/lib/python3.12/site-packages (from datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (3.20.3)\n",
      "Requirement already satisfied: pyarrow>=21.0.0 in /home/johan/git/Trainingdata/venv/lib/python3.12/site-packages (from datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (23.0.0)\n",
      "Requirement already satisfied: dill<0.4.1,>=0.3.0 in /home/johan/git/Trainingdata/venv/lib/python3.12/site-packages (from datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.4.0)\n",
      "Requirement already satisfied: pandas in /home/johan/git/Trainingdata/venv/lib/python3.12/site-packages (from datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (3.0.0)\n",
      "Requirement already satisfied: requests>=2.32.2 in /home/johan/git/Trainingdata/venv/lib/python3.12/site-packages (from datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2.32.5)\n",
      "Requirement already satisfied: httpx<1.0.0 in /home/johan/git/Trainingdata/venv/lib/python3.12/site-packages (from datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.28.1)\n",
      "Requirement already satisfied: xxhash in /home/johan/git/Trainingdata/venv/lib/python3.12/site-packages (from datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (3.6.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /home/johan/git/Trainingdata/venv/lib/python3.12/site-packages (from datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2025.9.0,>=2023.1.0 in /home/johan/git/Trainingdata/venv/lib/python3.12/site-packages (from fsspec[http]<=2025.9.0,>=2023.1.0->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2025.9.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/johan/git/Trainingdata/venv/lib/python3.12/site-packages (from datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (6.0.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/johan/git/Trainingdata/venv/lib/python3.12/site-packages (from huggingface_hub>=0.34.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (4.15.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /home/johan/git/Trainingdata/venv/lib/python3.12/site-packages (from huggingface_hub>=0.34.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (1.2.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/johan/git/Trainingdata/venv/lib/python3.12/site-packages (from transformers!=4.52.0,!=4.52.1,!=4.52.2,!=4.52.3,!=4.53.0,!=4.54.0,!=4.55.0,!=4.55.1,!=4.57.0,!=4.57.4,!=4.57.5,<=4.57.6,>=4.51.3->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2026.1.15)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /home/johan/git/Trainingdata/venv/lib/python3.12/site-packages (from transformers!=4.52.0,!=4.52.1,!=4.52.2,!=4.52.3,!=4.53.0,!=4.54.0,!=4.55.0,!=4.55.1,!=4.57.0,!=4.57.4,!=4.57.5,<=4.57.6,>=4.51.3->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.22.2)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /home/johan/git/Trainingdata/venv/lib/python3.12/site-packages (from transformers!=4.52.0,!=4.52.1,!=4.52.2,!=4.52.3,!=4.53.0,!=4.54.0,!=4.55.0,!=4.55.1,!=4.57.0,!=4.57.4,!=4.57.5,<=4.57.6,>=4.51.3->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.7.0)\n",
      "Requirement already satisfied: torchao>=0.13.0 in /home/johan/git/Trainingdata/venv/lib/python3.12/site-packages (from unsloth_zoo>=2026.1.4->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.15.0)\n",
      "Requirement already satisfied: triton>=3.0.0 in /home/johan/git/Trainingdata/venv/lib/python3.12/site-packages (from unsloth_zoo>=2026.1.4->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (3.6.0)\n",
      "Requirement already satisfied: accelerate>=0.34.1 in /home/johan/git/Trainingdata/venv/lib/python3.12/site-packages (from unsloth_zoo>=2026.1.4->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (1.12.0)\n",
      "Requirement already satisfied: trl!=0.19.0,<=0.24.0,>=0.18.2 in /home/johan/git/Trainingdata/venv/lib/python3.12/site-packages (from unsloth_zoo>=2026.1.4->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.24.0)\n",
      "Requirement already satisfied: peft!=0.11.0,>=0.18.0 in /home/johan/git/Trainingdata/venv/lib/python3.12/site-packages (from unsloth_zoo>=2026.1.4->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.18.1)\n",
      "Requirement already satisfied: cut_cross_entropy in /home/johan/git/Trainingdata/venv/lib/python3.12/site-packages (from unsloth_zoo>=2026.1.4->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (25.1.1)\n",
      "Requirement already satisfied: pillow in /home/johan/git/Trainingdata/venv/lib/python3.12/site-packages (from unsloth_zoo>=2026.1.4->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (12.1.0)\n",
      "Requirement already satisfied: msgspec in /home/johan/git/Trainingdata/venv/lib/python3.12/site-packages (from unsloth_zoo>=2026.1.4->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.20.0)\n",
      "Requirement already satisfied: scikit-learn in /home/johan/git/Trainingdata/venv/lib/python3.12/site-packages (from sentence-transformers->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (1.8.0)\n",
      "Requirement already satisfied: scipy in /home/johan/git/Trainingdata/venv/lib/python3.12/site-packages (from sentence-transformers->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (1.17.0)\n",
      "Requirement already satisfied: docstring-parser>=0.15 in /home/johan/git/Trainingdata/venv/lib/python3.12/site-packages (from tyro->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.17.0)\n",
      "Requirement already satisfied: typeguard>=4.0.0 in /home/johan/git/Trainingdata/venv/lib/python3.12/site-packages (from tyro->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (4.4.4)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /home/johan/git/Trainingdata/venv/lib/python3.12/site-packages (from fsspec[http]<=2025.9.0,>=2023.1.0->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (3.13.3)\n",
      "Requirement already satisfied: anyio in /home/johan/git/Trainingdata/venv/lib/python3.12/site-packages (from httpx<1.0.0->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (4.12.1)\n",
      "Requirement already satisfied: certifi in /home/johan/git/Trainingdata/venv/lib/python3.12/site-packages (from httpx<1.0.0->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2026.1.4)\n",
      "Requirement already satisfied: httpcore==1.* in /home/johan/git/Trainingdata/venv/lib/python3.12/site-packages (from httpx<1.0.0->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (1.0.9)\n",
      "Requirement already satisfied: idna in /home/johan/git/Trainingdata/venv/lib/python3.12/site-packages (from httpx<1.0.0->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (3.11)\n",
      "Requirement already satisfied: h11>=0.16 in /home/johan/git/Trainingdata/venv/lib/python3.12/site-packages (from httpcore==1.*->httpx<1.0.0->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.16.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /home/johan/git/Trainingdata/venv/lib/python3.12/site-packages (from requests>=2.32.2->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (3.4.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/johan/git/Trainingdata/venv/lib/python3.12/site-packages (from requests>=2.32.2->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2.6.3)\n",
      "Requirement already satisfied: setuptools in /home/johan/git/Trainingdata/venv/lib/python3.12/site-packages (from torch<3,>=2.3->bitsandbytes!=0.46.0,!=0.48.0,>=0.45.5->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (80.10.2)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /home/johan/git/Trainingdata/venv/lib/python3.12/site-packages (from torch<3,>=2.3->bitsandbytes!=0.46.0,!=0.48.0,>=0.45.5->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (1.14.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in /home/johan/git/Trainingdata/venv/lib/python3.12/site-packages (from torch<3,>=2.3->bitsandbytes!=0.46.0,!=0.48.0,>=0.45.5->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (3.6.1)\n",
      "Requirement already satisfied: jinja2 in /home/johan/git/Trainingdata/venv/lib/python3.12/site-packages (from torch<3,>=2.3->bitsandbytes!=0.46.0,!=0.48.0,>=0.45.5->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (3.1.6)\n",
      "Requirement already satisfied: cuda-bindings==12.9.4 in /home/johan/git/Trainingdata/venv/lib/python3.12/site-packages (from torch<3,>=2.3->bitsandbytes!=0.46.0,!=0.48.0,>=0.45.5->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (12.9.4)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.8.93 in /home/johan/git/Trainingdata/venv/lib/python3.12/site-packages (from torch<3,>=2.3->bitsandbytes!=0.46.0,!=0.48.0,>=0.45.5->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (12.8.93)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.8.90 in /home/johan/git/Trainingdata/venv/lib/python3.12/site-packages (from torch<3,>=2.3->bitsandbytes!=0.46.0,!=0.48.0,>=0.45.5->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.8.90 in /home/johan/git/Trainingdata/venv/lib/python3.12/site-packages (from torch<3,>=2.3->bitsandbytes!=0.46.0,!=0.48.0,>=0.45.5->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /home/johan/git/Trainingdata/venv/lib/python3.12/site-packages (from torch<3,>=2.3->bitsandbytes!=0.46.0,!=0.48.0,>=0.45.5->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (9.10.2.21)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.8.4.1 in /home/johan/git/Trainingdata/venv/lib/python3.12/site-packages (from torch<3,>=2.3->bitsandbytes!=0.46.0,!=0.48.0,>=0.45.5->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (12.8.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.3.83 in /home/johan/git/Trainingdata/venv/lib/python3.12/site-packages (from torch<3,>=2.3->bitsandbytes!=0.46.0,!=0.48.0,>=0.45.5->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (11.3.3.83)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.9.90 in /home/johan/git/Trainingdata/venv/lib/python3.12/site-packages (from torch<3,>=2.3->bitsandbytes!=0.46.0,!=0.48.0,>=0.45.5->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (10.3.9.90)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.3.90 in /home/johan/git/Trainingdata/venv/lib/python3.12/site-packages (from torch<3,>=2.3->bitsandbytes!=0.46.0,!=0.48.0,>=0.45.5->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (11.7.3.90)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.8.93 in /home/johan/git/Trainingdata/venv/lib/python3.12/site-packages (from torch<3,>=2.3->bitsandbytes!=0.46.0,!=0.48.0,>=0.45.5->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (12.5.8.93)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /home/johan/git/Trainingdata/venv/lib/python3.12/site-packages (from torch<3,>=2.3->bitsandbytes!=0.46.0,!=0.48.0,>=0.45.5->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.7.1)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /home/johan/git/Trainingdata/venv/lib/python3.12/site-packages (from torch<3,>=2.3->bitsandbytes!=0.46.0,!=0.48.0,>=0.45.5->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2.27.5)\n",
      "Requirement already satisfied: nvidia-nvshmem-cu12==3.4.5 in /home/johan/git/Trainingdata/venv/lib/python3.12/site-packages (from torch<3,>=2.3->bitsandbytes!=0.46.0,!=0.48.0,>=0.45.5->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (3.4.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.8.90 in /home/johan/git/Trainingdata/venv/lib/python3.12/site-packages (from torch<3,>=2.3->bitsandbytes!=0.46.0,!=0.48.0,>=0.45.5->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (12.8.90)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.8.93 in /home/johan/git/Trainingdata/venv/lib/python3.12/site-packages (from torch<3,>=2.3->bitsandbytes!=0.46.0,!=0.48.0,>=0.45.5->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (12.8.93)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.13.1.3 in /home/johan/git/Trainingdata/venv/lib/python3.12/site-packages (from torch<3,>=2.3->bitsandbytes!=0.46.0,!=0.48.0,>=0.45.5->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (1.13.1.3)\n",
      "Requirement already satisfied: cuda-pathfinder~=1.1 in /home/johan/git/Trainingdata/venv/lib/python3.12/site-packages (from cuda-bindings==12.9.4->torch<3,>=2.3->bitsandbytes!=0.46.0,!=0.48.0,>=0.45.5->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (1.3.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/johan/git/Trainingdata/venv/lib/python3.12/site-packages (from pandas->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2.9.0.post0)\n",
      "Requirement already satisfied: joblib>=1.3.0 in /home/johan/git/Trainingdata/venv/lib/python3.12/site-packages (from scikit-learn->sentence-transformers->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (1.5.3)\n",
      "Requirement already satisfied: threadpoolctl>=3.2.0 in /home/johan/git/Trainingdata/venv/lib/python3.12/site-packages (from scikit-learn->sentence-transformers->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (3.6.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /home/johan/git/Trainingdata/venv/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in /home/johan/git/Trainingdata/venv/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/johan/git/Trainingdata/venv/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (25.4.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/johan/git/Trainingdata/venv/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (1.8.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/johan/git/Trainingdata/venv/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (6.7.1)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /home/johan/git/Trainingdata/venv/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.4.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /home/johan/git/Trainingdata/venv/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (1.22.0)\n",
      "Requirement already satisfied: six>=1.5 in /home/johan/git/Trainingdata/venv/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (1.17.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/johan/git/Trainingdata/venv/lib/python3.12/site-packages (from sympy>=1.13.3->torch<3,>=2.3->bitsandbytes!=0.46.0,!=0.48.0,>=0.45.5->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/johan/git/Trainingdata/venv/lib/python3.12/site-packages (from jinja2->torch<3,>=2.3->bitsandbytes!=0.46.0,!=0.48.0,>=0.45.5->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (3.0.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: torchvision in /home/johan/git/Trainingdata/venv/lib/python3.12/site-packages (0.25.0)\n",
      "Requirement already satisfied: numpy in /home/johan/git/Trainingdata/venv/lib/python3.12/site-packages (from torchvision) (2.4.1)\n",
      "Requirement already satisfied: torch==2.10.0 in /home/johan/git/Trainingdata/venv/lib/python3.12/site-packages (from torchvision) (2.10.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /home/johan/git/Trainingdata/venv/lib/python3.12/site-packages (from torchvision) (12.1.0)\n",
      "Requirement already satisfied: filelock in /home/johan/git/Trainingdata/venv/lib/python3.12/site-packages (from torch==2.10.0->torchvision) (3.20.3)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /home/johan/git/Trainingdata/venv/lib/python3.12/site-packages (from torch==2.10.0->torchvision) (4.15.0)\n",
      "Requirement already satisfied: setuptools in /home/johan/git/Trainingdata/venv/lib/python3.12/site-packages (from torch==2.10.0->torchvision) (80.10.2)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /home/johan/git/Trainingdata/venv/lib/python3.12/site-packages (from torch==2.10.0->torchvision) (1.14.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in /home/johan/git/Trainingdata/venv/lib/python3.12/site-packages (from torch==2.10.0->torchvision) (3.6.1)\n",
      "Requirement already satisfied: jinja2 in /home/johan/git/Trainingdata/venv/lib/python3.12/site-packages (from torch==2.10.0->torchvision) (3.1.6)\n",
      "Requirement already satisfied: fsspec>=0.8.5 in /home/johan/git/Trainingdata/venv/lib/python3.12/site-packages (from torch==2.10.0->torchvision) (2025.9.0)\n",
      "Requirement already satisfied: cuda-bindings==12.9.4 in /home/johan/git/Trainingdata/venv/lib/python3.12/site-packages (from torch==2.10.0->torchvision) (12.9.4)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.8.93 in /home/johan/git/Trainingdata/venv/lib/python3.12/site-packages (from torch==2.10.0->torchvision) (12.8.93)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.8.90 in /home/johan/git/Trainingdata/venv/lib/python3.12/site-packages (from torch==2.10.0->torchvision) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.8.90 in /home/johan/git/Trainingdata/venv/lib/python3.12/site-packages (from torch==2.10.0->torchvision) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /home/johan/git/Trainingdata/venv/lib/python3.12/site-packages (from torch==2.10.0->torchvision) (9.10.2.21)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.8.4.1 in /home/johan/git/Trainingdata/venv/lib/python3.12/site-packages (from torch==2.10.0->torchvision) (12.8.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.3.83 in /home/johan/git/Trainingdata/venv/lib/python3.12/site-packages (from torch==2.10.0->torchvision) (11.3.3.83)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.9.90 in /home/johan/git/Trainingdata/venv/lib/python3.12/site-packages (from torch==2.10.0->torchvision) (10.3.9.90)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.3.90 in /home/johan/git/Trainingdata/venv/lib/python3.12/site-packages (from torch==2.10.0->torchvision) (11.7.3.90)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.8.93 in /home/johan/git/Trainingdata/venv/lib/python3.12/site-packages (from torch==2.10.0->torchvision) (12.5.8.93)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /home/johan/git/Trainingdata/venv/lib/python3.12/site-packages (from torch==2.10.0->torchvision) (0.7.1)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /home/johan/git/Trainingdata/venv/lib/python3.12/site-packages (from torch==2.10.0->torchvision) (2.27.5)\n",
      "Requirement already satisfied: nvidia-nvshmem-cu12==3.4.5 in /home/johan/git/Trainingdata/venv/lib/python3.12/site-packages (from torch==2.10.0->torchvision) (3.4.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.8.90 in /home/johan/git/Trainingdata/venv/lib/python3.12/site-packages (from torch==2.10.0->torchvision) (12.8.90)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.8.93 in /home/johan/git/Trainingdata/venv/lib/python3.12/site-packages (from torch==2.10.0->torchvision) (12.8.93)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.13.1.3 in /home/johan/git/Trainingdata/venv/lib/python3.12/site-packages (from torch==2.10.0->torchvision) (1.13.1.3)\n",
      "Requirement already satisfied: triton==3.6.0 in /home/johan/git/Trainingdata/venv/lib/python3.12/site-packages (from torch==2.10.0->torchvision) (3.6.0)\n",
      "Requirement already satisfied: cuda-pathfinder~=1.1 in /home/johan/git/Trainingdata/venv/lib/python3.12/site-packages (from cuda-bindings==12.9.4->torch==2.10.0->torchvision) (1.3.3)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/johan/git/Trainingdata/venv/lib/python3.12/site-packages (from sympy>=1.13.3->torch==2.10.0->torchvision) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/johan/git/Trainingdata/venv/lib/python3.12/site-packages (from jinja2->torch==2.10.0->torchvision) (3.0.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install \"unsloth[colab-new] @ git+https://github.com/unslothai/unsloth.git\"\n",
    "%pip install torchvision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ¦¥ Unsloth: Will patch your computer to enable 2x faster free finetuning.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/johan/git/Trainingdata/venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ¦¥ Unsloth Zoo will now patch everything to make training faster!\n"
     ]
    }
   ],
   "source": [
    "from unsloth import FastLanguageModel\n",
    "import torch\n",
    "import json\n",
    "from datasets import Dataset\n",
    "from trl import SFTTrainer\n",
    "from transformers import TrainingArguments\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Model configuration\nmax_seq_length = 2048  # Unsloth supports RoPE Scaling internally\ndtype = None  # None for auto detection. Float16 for Tesla T4, V100, Bfloat16 for Ampere+\nload_in_4bit = True  # Use 4bit quantization to reduce memory usage\n\n# Training configuration - IMPROVED for better quality\nEPOCHS = 4  # Increased from 2 for larger dataset (1884 examples)\nBATCH_SIZE = 2\nGRADIENT_ACCUMULATION_STEPS = 4\nLEARNING_RATE = 1e-4  # Reduced for more stable training with larger dataset\nMAX_STEPS = -1  # Set to -1 for full training\nWARMUP_STEPS = 50  # Increased warmup for larger dataset\n\n# Train/validation split\nVALIDATION_SPLIT = 0.05  # Use 5% for validation\n\n# Paths\nDATA_PATH = \"../data/english_to_swedish_poetry_translation.json\"\nOUTPUT_DIR = \"./outputs/translation_model\"\n\nprint(f\"Configuration:\")\nprint(f\"  Epochs: {EPOCHS}\")\nprint(f\"  Batch size: {BATCH_SIZE}\")\nprint(f\"  Gradient accumulation: {GRADIENT_ACCUMULATION_STEPS}\")\nprint(f\"  Effective batch size: {BATCH_SIZE * GRADIENT_ACCUMULATION_STEPS}\")\nprint(f\"  Learning rate: {LEARNING_RATE}\")\nprint(f\"  Warmup steps: {WARMUP_STEPS}\")\nprint(f\"  Validation split: {VALIDATION_SPLIT * 100}%\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth 2026.1.4: Fast Llama patching. Transformers: 4.57.6.\n",
      "   \\\\   /|    NVIDIA GeForce RTX 3060. Num GPUs = 1. Max memory: 11.633 GB. Platform: Linux.\n",
      "O^O/ \\_/ \\    Torch: 2.10.0+cu128. CUDA: 8.6. CUDA Toolkit: 12.8. Triton: 3.6.0\n",
      "\\        /    Bfloat16 = TRUE. FA [Xformers = None. FA2 = False]\n",
      " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
      "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n",
      "Model loaded: llama\n",
      "Vocabulary size: 128256\n"
     ]
    }
   ],
   "source": [
    "# Load model with Unsloth optimizations\n",
    "model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "    model_name=\"unsloth/llama-3.2-3b-instruct\",  # Choose from Unsloth's optimized models\n",
    "    max_seq_length=max_seq_length,\n",
    "    dtype=dtype,\n",
    "    load_in_4bit=load_in_4bit,\n",
    ")\n",
    "\n",
    "print(f\"Model loaded: {model.config.model_type}\")\n",
    "print(f\"Vocabulary size: {len(tokenizer)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Configure LoRA for Fine-tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Add LoRA adapters for efficient fine-tuning\n# IMPROVED: Higher rank for better quality with larger dataset\nmodel = FastLanguageModel.get_peft_model(\n    model,\n    r=32,  # LoRA rank - increased from 16 for better quality\n    target_modules=[\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n                    \"gate_proj\", \"up_proj\", \"down_proj\"],\n    lora_alpha=32,  # Increased to match rank\n    lora_dropout=0,  # Supports any, but = 0 is optimized\n    bias=\"none\",     # Supports any, but = \"none\" is optimized\n    use_gradient_checkpointing=\"unsloth\",  # True or \"unsloth\" for very long context\n    random_state=3407,\n    use_rslora=True,  # Enable Rank Stabilized LoRA for better training\n    loftq_config=None, # LoftQ\n)\n\nprint(\"LoRA adapters configured with rank=32 and RSLoRA enabled\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Load and Prepare Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 790 training examples\n",
      "\n",
      "Example entry:\n",
      "Instruction: Translate the following English poem to Swedish.\n",
      "Input: Invocation\n",
      "\n",
      "O Muse! my foam-born sister!\n",
      "Thou only god, at whose altar\n",
      "I trust and offer.\n",
      "Thou, who ...\n",
      "Output: Ã…kallan\n",
      "\n",
      "O musa! Min skum-fÃ¶dda syster!\n",
      "Du enda gud, till hvars altare\n",
      "jag tror och offrar.\n",
      "Du, som ...\n"
     ]
    }
   ],
   "source": [
    "# Load the alpaca-formatted JSON data\n",
    "with open(DATA_PATH, 'r', encoding='utf-8') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "print(f\"Loaded {len(data)} training examples\")\n",
    "print(f\"\\nExample entry:\")\n",
    "print(f\"Instruction: {data[0]['instruction']}\")\n",
    "print(f\"Input: {data[0]['input'][:100]}...\")\n",
    "print(f\"Output: {data[0]['output'][:100]}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 790/790 [00:00<00:00, 90057.90 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total examples: 790\n",
      "Training examples: 750\n",
      "Validation examples: 40\n",
      "\n",
      "Formatted example (first 500 chars):\n",
      "Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "Translate the following English text to Swedish.\n",
      "\n",
      "### Input:\n",
      "The Trumpets\n",
      "I am the trumpeter\n",
      "\n",
      "### Response:\n",
      "Trumpetaren\n",
      "Jag Ã¤r trumpetaren<|eot_id|>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Define the alpaca prompt template\n",
    "alpaca_prompt = \"\"\"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n",
    "\n",
    "### Instruction:\n",
    "{}\n",
    "\n",
    "### Input:\n",
    "{}\n",
    "\n",
    "### Response:\n",
    "{}\"\"\"\n",
    "\n",
    "EOS_TOKEN = tokenizer.eos_token  # Must add EOS_TOKEN\n",
    "\n",
    "def formatting_prompts_func(examples):\n",
    "    instructions = examples[\"instruction\"]\n",
    "    inputs       = examples[\"input\"]\n",
    "    outputs      = examples[\"output\"]\n",
    "    texts = []\n",
    "    for instruction, input, output in zip(instructions, inputs, outputs):\n",
    "        # Must add EOS_TOKEN, otherwise generation will go on forever\n",
    "        text = alpaca_prompt.format(instruction, input, output) + EOS_TOKEN\n",
    "        texts.append(text)\n",
    "    return {\"text\": texts}\n",
    "\n",
    "# Convert to HuggingFace Dataset\n",
    "dataset = Dataset.from_list(data)\n",
    "dataset = dataset.map(formatting_prompts_func, batched=True)\n",
    "\n",
    "# Split into train and validation\n",
    "dataset_split = dataset.train_test_split(test_size=VALIDATION_SPLIT, seed=3407)\n",
    "train_dataset = dataset_split['train']\n",
    "eval_dataset = dataset_split['test']\n",
    "\n",
    "print(f\"Total examples: {len(dataset)}\")\n",
    "print(f\"Training examples: {len(train_dataset)}\")\n",
    "print(f\"Validation examples: {len(eval_dataset)}\")\n",
    "print(f\"\\nFormatted example (first 500 chars):\")\n",
    "print(train_dataset[0]['text'][:500])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Configure Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "trainer = SFTTrainer(\n    model=model,\n    tokenizer=tokenizer,\n    train_dataset=train_dataset,\n    eval_dataset=eval_dataset,\n    dataset_text_field=\"text\",\n    max_seq_length=max_seq_length,\n    dataset_num_proc=2,\n    packing=False,  # Can make training 5x faster for short sequences\n    args=TrainingArguments(\n        per_device_train_batch_size=BATCH_SIZE,\n        per_device_eval_batch_size=BATCH_SIZE,\n        gradient_accumulation_steps=GRADIENT_ACCUMULATION_STEPS,\n        warmup_steps=WARMUP_STEPS,\n        max_steps=MAX_STEPS,\n        num_train_epochs=EPOCHS,\n        learning_rate=LEARNING_RATE,\n        fp16=not torch.cuda.is_bf16_supported(),\n        bf16=torch.cuda.is_bf16_supported(),\n        logging_steps=10,  # Log every 10 steps\n        eval_strategy=\"steps\",  # Evaluate during training\n        eval_steps=100,  # Evaluate every 100 steps (larger dataset)\n        save_strategy=\"steps\",  # Save during training\n        save_steps=100,  # Save every 100 steps\n        optim=\"adamw_8bit\",\n        weight_decay=0.01,\n        lr_scheduler_type=\"cosine\",  # Cosine schedule for smoother training\n        seed=3407,\n        output_dir=OUTPUT_DIR,\n        save_total_limit=3,  # Keep 3 checkpoints\n        load_best_model_at_end=True,  # Load best model after training\n        metric_for_best_model=\"eval_loss\",\n    ),\n)\n\nprint(\"Trainer configured\")\nprint(f\"Effective batch size: {BATCH_SIZE * GRADIENT_ACCUMULATION_STEPS}\")\nprint(f\"Total training steps per epoch: {len(train_dataset) // (BATCH_SIZE * GRADIENT_ACCUMULATION_STEPS)}\")\nprint(f\"Total training steps: {len(train_dataset) // (BATCH_SIZE * GRADIENT_ACCUMULATION_STEPS) * EPOCHS}\")\nprint(f\"Evaluation every 100 steps\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU = NVIDIA GeForce RTX 3060. Max memory = 11.633 GB.\n",
      "3.07 GB of memory reserved.\n"
     ]
    }
   ],
   "source": [
    "# Show GPU stats before training\n",
    "gpu_stats = torch.cuda.get_device_properties(0)\n",
    "start_gpu_memory = round(torch.cuda.max_memory_reserved() / 1024 / 1024 / 1024, 3)\n",
    "max_memory = round(gpu_stats.total_memory / 1024 / 1024 / 1024, 3)\n",
    "print(f\"GPU = {gpu_stats.name}. Max memory = {max_memory} GB.\")\n",
    "print(f\"{start_gpu_memory} GB of memory reserved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The model is already on multiple devices. Skipping the move to device specified in `args`.\n",
      "==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1\n",
      "   \\\\   /|    Num examples = 750 | Num Epochs = 2 | Total steps = 188\n",
      "O^O/ \\_/ \\    Batch size per device = 2 | Gradient accumulation steps = 4\n",
      "\\        /    Data Parallel GPUs = 1 | Total batch size (2 x 4 x 1) = 8\n",
      " \"-____-\"     Trainable parameters = 24,313,856 of 3,237,063,680 (0.75% trained)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='188' max='188' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [188/188 03:53, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.951600</td>\n",
       "      <td>0.961267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.628700</td>\n",
       "      <td>0.750344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.513300</td>\n",
       "      <td>0.618352</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unsloth: Not an error, but LlamaForCausalLM does not accept `num_items_in_batch`.\n",
      "Using gradient accumulation will be very slightly less accurate.\n",
      "Read more on gradient accumulation issues here: https://unsloth.ai/blog/gradient\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Peak reserved memory = 6.225 GB.\n",
      "Peak reserved memory for training = 3.155 GB.\n",
      "Peak reserved memory % of max memory = 53.512 %.\n",
      "Peak reserved memory for training % of max memory = 27.121 %.\n"
     ]
    }
   ],
   "source": [
    "# Start training\n",
    "trainer_stats = trainer.train()\n",
    "\n",
    "# Show final memory and time stats\n",
    "used_memory = round(torch.cuda.max_memory_reserved() / 1024 / 1024 / 1024, 3)\n",
    "used_memory_for_lora = round(used_memory - start_gpu_memory, 3)\n",
    "used_percentage = round(used_memory / max_memory * 100, 3)\n",
    "lora_percentage = round(used_memory_for_lora / max_memory * 100, 3)\n",
    "\n",
    "print(f\"Peak reserved memory = {used_memory} GB.\")\n",
    "print(f\"Peak reserved memory for training = {used_memory_for_lora} GB.\")\n",
    "print(f\"Peak reserved memory % of max memory = {used_percentage} %.\")\n",
    "print(f\"Peak reserved memory for training % of max memory = {lora_percentage} %.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Test the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Enable native 2x faster inference\nFastLanguageModel.for_inference(model)\n\n# Test translation with modern poetry style\ntest_instruction = \"Translate the following English poem to Swedish.\"\ntest_input = \"\"\"Two o'clock: moonlight. The train has stopped\nout in the middle of the plain. Far away, points of light in a town,\nflickering cold at the horizon.\n\nAs when someone has gone into a dream so deep\nshe'll never remember having been there\nwhen she returns to her room.\"\"\"\n\n# Format the input\nprompt = alpaca_prompt.format(\n    test_instruction,\n    test_input,\n    \"\",  # output - leave blank for generation\n)\n\ninputs = tokenizer([prompt], return_tensors=\"pt\").to(\"cuda\")\n\nprint(\"Testing translation...\\n\")\nprint(f\"Input English text:\\n{test_input}\\n\")\nprint(\"=\" * 50)\n\noutputs = model.generate(\n    **inputs,\n    max_new_tokens=256,\n    use_cache=True,\n    temperature=0.7,\n    top_p=0.9,\n)\n\ndecoded_output = tokenizer.batch_decode(outputs, skip_special_tokens=True)[0]\n\n# Extract just the response part\nresponse = decoded_output.split(\"### Response:\")[-1].strip()\n\nprint(f\"\\nSwedish translation:\\n{response}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. More Test Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "def translate_to_swedish(english_text):\n    \"\"\"Helper function to translate English poetry to Swedish\"\"\"\n    prompt = alpaca_prompt.format(\n        \"Translate the following English text to Swedish.\",\n        english_text,\n        \"\",\n    )\n    \n    inputs = tokenizer([prompt], return_tensors=\"pt\").to(\"cuda\")\n    outputs = model.generate(\n        **inputs,\n        max_new_tokens=256,\n        use_cache=True,\n        temperature=0.7,\n        top_p=0.9,\n    )\n    \n    decoded = tokenizer.batch_decode(outputs, skip_special_tokens=True)[0]\n    response = decoded.split(\"### Response:\")[-1].strip()\n    return response\n\n# Test with modern poetry examples\ntest_examples = [\n    \"I believe in the solitary human being, in her who walks alone.\",\n    \"Spring lies desolate. The velvet-dark ditch crawls by my side without reflections.\",\n    \"The snow falls slowly over the sleeping houses.\",\n    \"There is a place beyond words where language cannot reach.\",\n    \"Yes, of course it hurts when buds are breaking.\",\n]\n\nprint(\"Testing multiple translations:\\n\")\nprint(\"=\" * 70)\n\nfor i, test in enumerate(test_examples, 1):\n    print(f\"\\nTest {i}:\")\n    print(f\"English: {test}\")\n    translation = translate_to_swedish(test)\n    print(f\"Swedish: {translation}\")\n    print(\"-\" * 70)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Save the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LoRA adapters saved to: translation_model_lora/\n"
     ]
    }
   ],
   "source": [
    "# Save LoRA adapters only (much smaller)\n",
    "model.save_pretrained(\"translation_model_lora\")\n",
    "tokenizer.save_pretrained(\"translation_model_lora\")\n",
    "\n",
    "print(\"LoRA adapters saved to: translation_model_lora/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found HuggingFace hub cache directory: /home/johan/.cache/huggingface/hub\n",
      "Checking cache directory for required files...\n",
      "Cache check failed: model-00001-of-00002.safetensors not found in local cache.\n",
      "Not all required files found in cache. Will proceed with downloading.\n",
      "Checking cache directory for required files...\n",
      "Cache check failed: tokenizer.model not found in local cache.\n",
      "Not all required files found in cache. Will proceed with downloading.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unsloth: Preparing safetensor model files: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 3748.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: tokenizer.model not found (this is OK for non-SentencePiece models)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unsloth: Merging weights into 16bit: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:51<00:00, 25.97s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unsloth: Merge process complete. Saved to `/home/johan/git/Trainingdata/notebooks/translation_model_merged_16bit`\n",
      "Merged 16-bit model saved to: translation_model_merged_16bit/\n"
     ]
    }
   ],
   "source": [
    "# Optional: Save merged model (base + LoRA) in 16bit\n",
    "# This creates a standalone model that doesn't need LoRA adapters\n",
    "model.save_pretrained_merged(\n",
    "    \"translation_model_merged_16bit\",\n",
    "    tokenizer,\n",
    "    save_method=\"merged_16bit\",\n",
    ")\n",
    "\n",
    "print(\"Merged 16-bit model saved to: translation_model_merged_16bit/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unsloth: Merging model weights to 16-bit format...\n",
      "Found HuggingFace hub cache directory: /home/johan/.cache/huggingface/hub\n",
      "Checking cache directory for required files...\n",
      "Cache check failed: model-00001-of-00002.safetensors not found in local cache.\n",
      "Not all required files found in cache. Will proceed with downloading.\n",
      "Checking cache directory for required files...\n",
      "Cache check failed: tokenizer.model not found in local cache.\n",
      "Not all required files found in cache. Will proceed with downloading.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unsloth: Preparing safetensor model files: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 1118.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: tokenizer.model not found (this is OK for non-SentencePiece models)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unsloth: Merging weights into 16bit: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [01:02<00:00, 31.39s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unsloth: Merge process complete. Saved to `/home/johan/git/Trainingdata/notebooks/translation_model`\n",
      "Unsloth: Converting to GGUF format...\n",
      "==((====))==  Unsloth: Conversion from HF to GGUF information\n",
      "   \\\\   /|    [0] Installing llama.cpp might take 3 minutes.\n",
      "O^O/ \\_/ \\    [1] Converting HF to GGUF bf16 might take 3 minutes.\n",
      "\\        /    [2] Converting GGUF bf16 to ['q4_k_m'] might take 10 minutes each.\n",
      " \"-____-\"     In total, you will have to wait at least 16 minutes.\n",
      "\n",
      "Unsloth: Installing llama.cpp. This might take 3 minutes...\n",
      "Unsloth: llama.cpp folder exists but binaries not found - will rebuild\n",
      "Unsloth: Updating system package directories\n",
      "Unsloth: All required system packages already installed!\n",
      "Unsloth: Install llama.cpp and building - please wait 1 to 3 minutes\n",
      "Unsloth: Install GGUF and other packages\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Unsloth: GGUF conversion failed: [FAIL] Command `pip install gguf protobuf sentencepiece mistral_common` failed with exit code 1\nstdout: \u001b[1;31merror\u001b[0m: \u001b[1mexternally-managed-environment\u001b[0m\n\n\u001b[31mÃ—\u001b[0m This environment is externally managed\n\u001b[31mâ•°â”€>\u001b[0m To install Python packages system-wide, try apt install\n\u001b[31m   \u001b[0m python3-xyz, where xyz is the package you are trying to\n\u001b[31m   \u001b[0m install.\n\u001b[31m   \u001b[0m \n\u001b[31m   \u001b[0m If you wish to install a non-Debian-packaged Python package,\n\u001b[31m   \u001b[0m create a virtual environment using python3 -m venv path/to/venv.\n\u001b[31m   \u001b[0m Then use path/to/venv/bin/python and path/to/venv/bin/pip. Make\n\u001b[31m   \u001b[0m sure you have python3-full installed.\n\u001b[31m   \u001b[0m \n\u001b[31m   \u001b[0m If you wish to install a non-Debian packaged Python application,\n\u001b[31m   \u001b[0m it may be easiest to use pipx install xyz, which will manage a\n\u001b[31m   \u001b[0m virtual environment for you. Make sure you have pipx installed.\n\u001b[31m   \u001b[0m \n\u001b[31m   \u001b[0m See /usr/share/doc/python3.12/README.venv for more information.\n\n\u001b[1;35mnote\u001b[0m: If you believe this is a mistake, please contact your Python installation or OS distribution provider. You can override this, at the risk of breaking your Python installation or OS, by passing --break-system-packages.\n\u001b[1;36mhint\u001b[0m: See PEP 668 for the detailed specification.\n\n",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/git/Trainingdata/venv/lib/python3.12/site-packages/unsloth/save.py:1201\u001b[39m, in \u001b[36msave_to_gguf\u001b[39m\u001b[34m(model_name, model_type, model_dtype, is_sentencepiece, model_directory, quantization_method, first_conversion, is_vlm, is_gpt_oss)\u001b[39m\n\u001b[32m   1200\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1201\u001b[39m     quantizer_location, converter_location = \u001b[43mcheck_llama_cpp\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1202\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mUnsloth: llama.cpp found in the system. Skipping installation.\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/git/Trainingdata/venv/lib/python3.12/site-packages/unsloth_zoo/llama_cpp.py:348\u001b[39m, in \u001b[36mcheck_llama_cpp\u001b[39m\u001b[34m(llama_cpp_folder)\u001b[39m\n\u001b[32m    347\u001b[39m     files_found = glob.glob(os.path.join(llama_cpp_folder, \u001b[33m\"\u001b[39m\u001b[33m*\u001b[39m\u001b[33m\"\u001b[39m))\n\u001b[32m--> \u001b[39m\u001b[32m348\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m    349\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mUnsloth: No working quantizer found in \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mllama_cpp_folder\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    350\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mFiles in directory: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m, \u001b[39m\u001b[33m'\u001b[39m.join(os.path.basename(f)\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mfor\u001b[39;00m\u001b[38;5;250m \u001b[39mf\u001b[38;5;250m \u001b[39m\u001b[38;5;129;01min\u001b[39;00m\u001b[38;5;250m \u001b[39mfiles_found[:\u001b[32m20\u001b[39m])\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    351\u001b[39m     )\n\u001b[32m    352\u001b[39m \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "\u001b[31mRuntimeError\u001b[39m: Unsloth: No working quantizer found in llama.cpp\nFiles in directory: pyrightconfig.json, tests, requirements.txt, Makefile, CLAUDE.md, build-xcframework.sh, CMakeLists.txt, LICENSE, common, mypy.ini, media, SECURITY.md, convert_llama_ggml_to_gguf.py, convert_hf_to_gguf.py, vendor, licenses, src, docs, README.md, convert_lora_to_gguf.py",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/git/Trainingdata/venv/lib/python3.12/site-packages/unsloth/save.py:1976\u001b[39m, in \u001b[36munsloth_save_pretrained_gguf\u001b[39m\u001b[34m(self, save_directory, tokenizer, quantization_method, first_conversion, push_to_hub, token, private, is_main_process, state_dict, save_function, max_shard_size, safe_serialization, variant, save_peft_format, tags, temporary_location, maximum_memory_usage)\u001b[39m\n\u001b[32m   1975\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1976\u001b[39m     all_file_locations, want_full_precision, is_vlm_update = \u001b[43msave_to_gguf\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1977\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1978\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmodel_type\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1979\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmodel_dtype\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1980\u001b[39m \u001b[43m        \u001b[49m\u001b[43mis_sentencepiece\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m   1981\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmodel_directory\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43msave_directory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1982\u001b[39m \u001b[43m        \u001b[49m\u001b[43mquantization_method\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mquantization_methods\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1983\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfirst_conversion\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mfirst_conversion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1984\u001b[39m \u001b[43m        \u001b[49m\u001b[43mis_vlm\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_vlm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Pass VLM flag\u001b[39;49;00m\n\u001b[32m   1985\u001b[39m \u001b[43m        \u001b[49m\u001b[43mis_gpt_oss\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_gpt_oss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Pass gpt_oss Flag\u001b[39;49;00m\n\u001b[32m   1986\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1987\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/git/Trainingdata/venv/lib/python3.12/site-packages/unsloth/save.py:1211\u001b[39m, in \u001b[36msave_to_gguf\u001b[39m\u001b[34m(model_name, model_type, model_dtype, is_sentencepiece, model_directory, quantization_method, first_conversion, is_vlm, is_gpt_oss)\u001b[39m\n\u001b[32m   1210\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1211\u001b[39m         quantizer_location, converter_location = \u001b[43minstall_llama_cpp\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1212\u001b[39m \u001b[43m            \u001b[49m\u001b[43mgpu_support\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# GGUF conversion doesn't need CUDA\u001b[39;49;00m\n\u001b[32m   1213\u001b[39m \u001b[43m            \u001b[49m\u001b[43mprint_output\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mprint_output\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1214\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1216\u001b[39m \u001b[38;5;66;03m# Step 2: Download and patch converter script\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/git/Trainingdata/venv/lib/python3.12/site-packages/unsloth_zoo/llama_cpp.py:420\u001b[39m, in \u001b[36minstall_llama_cpp\u001b[39m\u001b[34m(llama_cpp_folder, llama_cpp_targets, print_output, gpu_support, just_clone_repo)\u001b[39m\n\u001b[32m    419\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mUnsloth: Install GGUF and other packages\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m420\u001b[39m \u001b[43mtry_execute\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43mf\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mpip\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m install gguf protobuf sentencepiece mistral_common\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    421\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m just_clone_repo: \u001b[38;5;28;01mreturn\u001b[39;00m llama_cpp_folder\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/git/Trainingdata/venv/lib/python3.12/site-packages/unsloth_zoo/llama_cpp.py:276\u001b[39m, in \u001b[36mtry_execute\u001b[39m\u001b[34m(command, sudo, print_output, print_outputs, cwd, system_type, ignore_deprecation)\u001b[39m\n\u001b[32m    275\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m stderr: error_msg += \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mstderr: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstderr\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m276\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(error_msg)\n\u001b[32m    278\u001b[39m \u001b[38;5;66;03m# Process output\u001b[39;00m\n",
      "\u001b[31mRuntimeError\u001b[39m: [FAIL] Command `pip install gguf protobuf sentencepiece mistral_common` failed with exit code 1\nstdout: \u001b[1;31merror\u001b[0m: \u001b[1mexternally-managed-environment\u001b[0m\n\n\u001b[31mÃ—\u001b[0m This environment is externally managed\n\u001b[31mâ•°â”€>\u001b[0m To install Python packages system-wide, try apt install\n\u001b[31m   \u001b[0m python3-xyz, where xyz is the package you are trying to\n\u001b[31m   \u001b[0m install.\n\u001b[31m   \u001b[0m \n\u001b[31m   \u001b[0m If you wish to install a non-Debian-packaged Python package,\n\u001b[31m   \u001b[0m create a virtual environment using python3 -m venv path/to/venv.\n\u001b[31m   \u001b[0m Then use path/to/venv/bin/python and path/to/venv/bin/pip. Make\n\u001b[31m   \u001b[0m sure you have python3-full installed.\n\u001b[31m   \u001b[0m \n\u001b[31m   \u001b[0m If you wish to install a non-Debian packaged Python application,\n\u001b[31m   \u001b[0m it may be easiest to use pipx install xyz, which will manage a\n\u001b[31m   \u001b[0m virtual environment for you. Make sure you have pipx installed.\n\u001b[31m   \u001b[0m \n\u001b[31m   \u001b[0m See /usr/share/doc/python3.12/README.venv for more information.\n\n\u001b[1;35mnote\u001b[0m: If you believe this is a mistake, please contact your Python installation or OS distribution provider. You can override this, at the risk of breaking your Python installation or OS, by passing --break-system-packages.\n\u001b[1;36mhint\u001b[0m: See PEP 668 for the detailed specification.\n\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[16]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Optional: Save as 4-bit quantized GGUF for llama.cpp\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;66;03m# Useful for running locally with CPU or smaller GPUs\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43msave_pretrained_gguf\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtranslation_model\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m    \u001b[49m\u001b[43mquantization_method\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mq4_k_m\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m      9\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mGGUF model saved to: translation_model/\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/git/Trainingdata/venv/lib/python3.12/site-packages/unsloth/save.py:1996\u001b[39m, in \u001b[36munsloth_save_pretrained_gguf\u001b[39m\u001b[34m(self, save_directory, tokenizer, quantization_method, first_conversion, push_to_hub, token, private, is_main_process, state_dict, save_function, max_shard_size, safe_serialization, variant, save_peft_format, tags, temporary_location, maximum_memory_usage)\u001b[39m\n\u001b[32m   1989\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m   1990\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mUnsloth: GGUF conversion failed in Kaggle environment.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m   1991\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mThis is likely due to the 20GB disk space limit.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m   1992\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mTry saving to /tmp directory or use a smaller model.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m   1993\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mError: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m   1994\u001b[39m         )\n\u001b[32m   1995\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1996\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mUnsloth: GGUF conversion failed: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m   1998\u001b[39m \u001b[38;5;66;03m# Step 9: Create Ollama modelfile\u001b[39;00m\n\u001b[32m   1999\u001b[39m modelfile_location = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[31mRuntimeError\u001b[39m: Unsloth: GGUF conversion failed: [FAIL] Command `pip install gguf protobuf sentencepiece mistral_common` failed with exit code 1\nstdout: \u001b[1;31merror\u001b[0m: \u001b[1mexternally-managed-environment\u001b[0m\n\n\u001b[31mÃ—\u001b[0m This environment is externally managed\n\u001b[31mâ•°â”€>\u001b[0m To install Python packages system-wide, try apt install\n\u001b[31m   \u001b[0m python3-xyz, where xyz is the package you are trying to\n\u001b[31m   \u001b[0m install.\n\u001b[31m   \u001b[0m \n\u001b[31m   \u001b[0m If you wish to install a non-Debian-packaged Python package,\n\u001b[31m   \u001b[0m create a virtual environment using python3 -m venv path/to/venv.\n\u001b[31m   \u001b[0m Then use path/to/venv/bin/python and path/to/venv/bin/pip. Make\n\u001b[31m   \u001b[0m sure you have python3-full installed.\n\u001b[31m   \u001b[0m \n\u001b[31m   \u001b[0m If you wish to install a non-Debian packaged Python application,\n\u001b[31m   \u001b[0m it may be easiest to use pipx install xyz, which will manage a\n\u001b[31m   \u001b[0m virtual environment for you. Make sure you have pipx installed.\n\u001b[31m   \u001b[0m \n\u001b[31m   \u001b[0m See /usr/share/doc/python3.12/README.venv for more information.\n\n\u001b[1;35mnote\u001b[0m: If you believe this is a mistake, please contact your Python installation or OS distribution provider. You can override this, at the risk of breaking your Python installation or OS, by passing --break-system-packages.\n\u001b[1;36mhint\u001b[0m: See PEP 668 for the detailed specification.\n\n"
     ]
    }
   ],
   "source": [
    "# Optional: Save as 4-bit quantized GGUF for llama.cpp\n",
    "# Useful for running locally with CPU or smaller GPUs\n",
    "model.save_pretrained_gguf(\n",
    "    \"translation_model\",\n",
    "    tokenizer,\n",
    "    quantization_method=\"q4_k_m\",\n",
    ")\n",
    "\n",
    "print(\"GGUF model saved to: translation_model/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Trainingdata (venv)",
   "language": "python",
   "name": "trainingdata-venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}